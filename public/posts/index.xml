<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Projects - Corentin LEGER</title>
        <link>http://example.org/posts/</link>
        <description>All Projects | Corentin LEGER</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 30 Sep 2024 11:00:59 -0400</lastBuildDate><atom:link href="http://example.org/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Software: Vivarium</title>
    <link>http://example.org/posts/vivarium/</link>
    <pubDate>Mon, 30 Sep 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/vivarium/</guid>
    <description><![CDATA[I am currently working on a project named Vivarium that serves both research and teaching in AI. It&rsquo;s a software that allows launching custom particle based multi-agents simulations, using a physics engine built in Jax. The simulations can be hosted on a server, and interacted with in real time from a web interface or Jupyter Notebooks. The Notebook case aims to teach students how to program behaviors of simulated robots with Python !]]></description>
</item>
<item>
    <title>Research: When LLMs Play the Telephone Game</title>
    <link>http://example.org/posts/telephonellm/</link>
    <pubDate>Fri, 05 Jul 2024 11:00:59 -0400</pubDate>
    <author>Jérémy Perez, Corentin Léger, Grgur Kovač, Cédric Colas, Gaia Molinaro, Maxime Derex, Pierre-Yves Oudeyer, Clément Moulin-Frier</author>
    <guid>http://example.org/posts/telephonellm/</guid>
    <description><![CDATA[Arxiv preprint (Under Review)
Abstract As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next. While significant research has examined individual LLM behaviors, existing studies have largely overlooked the collective behaviors and information distortions arising from iterated LLM interactions. Small biases, negligible at the single output level, risk being amplified in iterated interactions, potentially leading the content to evolve towards attractor states.]]></description>
</item>
<item>
    <title>Software: Open Source Contributions</title>
    <link>http://example.org/posts/opensource/</link>
    <pubDate>Wed, 12 Jun 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/opensource/</guid>
    <description><![CDATA[Developed the LLM-Culture library. This software enables simulating networks composed of LLMs agents, that can generate text over multiple generations based on their neighbors input, personnality and task. The project also provides tools for analyzing the resulting text dynamics and offers an user-friendly web interface, making it accessible to non-programmers.
Developed a turorial for hyper parameter search using Optuna in the ReservoirPy machine learning library. The tutorial covers sequential and parallelized hyperparameter search on local machines using the joblib package.]]></description>
</item>
<item>
    <title>Research: Cultural evolution in populations of Large Language Models</title>
    <link>http://example.org/posts/llm_culture/</link>
    <pubDate>Tue, 12 Mar 2024 11:00:59 -0400</pubDate>
    <author>Jérémy Perez, Corentin Léger, Marcela Ovando-Tellez, Chris Foulon, Joan Dussauld, Pierre-Yves Oudeyer, Clément Moulin-Frier</author>
    <guid>http://example.org/posts/llm_culture/</guid>
    <description><![CDATA[Arxiv preprint. We are currently working on the paper to submit it to a conference.
Abstract Research in cultural evolution aims at providing causal explanations for the change of culture over time. Over the past decades, this field has generated an important body of knowledge, using experimental, historical, and computational methods. While computational models have been very successful at generating testable hypotheses about the effects of several factors, such as population structure or transmission biases, some phenomena have so far been more complex to capture using agent-based and formal models.]]></description>
</item>
<item>
    <title>Software: Simulation Sandbox</title>
    <link>http://example.org/posts/simulationsandbox/</link>
    <pubDate>Tue, 30 Jan 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/simulationsandbox/</guid>
    <description><![CDATA[SimulationSandbox is a simple framework built with Jax and Socket that allows for real-time interaction between a simulation hosted on a server and multiple clients. It provides a simple interface for visualizing or interacting with the state of a hosted simulation from remote clients, such as jupyter notebooks.
Code]]></description>
</item>
<item>
    <title>Research: Evolving Reservoirs for Meta Reinforcement Learning</title>
    <link>http://example.org/posts/er_mrl/</link>
    <pubDate>Tue, 12 Dec 2023 11:00:59 -0400</pubDate>
    <author>Corentin Léger*, Gautier Hamon*, Eleni Nisioti, Xavier Hinaut, Clément Moulin-Frier</author>
    <guid>http://example.org/posts/er_mrl/</guid>
    <description><![CDATA[Paper presented at EvoStar 2024 (Long Talk).
Abstract Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning.
In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development.]]></description>
</item>
<item>
    <title>Hackathon: Ebiose</title>
    <link>http://example.org/posts/ebiose/</link>
    <pubDate>Fri, 17 Nov 2023 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/ebiose/</guid>
    <description><![CDATA[Introduction Participated to a project called Ebiose during a 2 days hackathon with a team of 4 people. It focuses on a multi-language-based-agent system to solve tasks. In this system, agents are composed of LLM (e.g. GPT-3.5) coupled with a specific prompt. The structure of the multi-agent system followes a predetermined sequence, where one agent answers a question, another verifies the answer, and a final agent synthesizes both responses. This collaboration is inspired by the Autogen Framework, emphasizing coordinated efforts among agents.]]></description>
</item>
<item>
    <title>Software: Rising Sun</title>
    <link>http://example.org/posts/risingsun/</link>
    <pubDate>Wed, 12 Jul 2023 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/risingsun/</guid>
    <description><![CDATA[To try to beat friends on the combat phases of the &ldquo;Rising Sun&rdquo; board game, I created this simplified gymnasium implementation of the game. The project also incorporates a python script to train a single RL agent on the environment. This agent can currently only be trained against hard-coded players (either random of with heuristics).
The next step will be to add multi-agents training to the project. Then, it will be interesting to explore the path of self play to see how complex the behaviors of the agent can become !]]></description>
</item>
<item>
    <title>Software: Genetic Algorithm for sport&#39;s pools optimization</title>
    <link>http://example.org/posts/evoopt/</link>
    <pubDate>Sat, 15 Apr 2023 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/evoopt/</guid>
    <description><![CDATA[As a volleyball player who frequently travels to play against teams in distant cities, I became curious about how sports pools are optimized to ensure fair and reasonable travel times for teams in the same category. To explore this further and delve into evolutionary algorithms, I embarked on a project to create a custom genetic algorithm using NumPy.
The custom genetic algorithm is designed to improve the current distribution of cities in sports pools.]]></description>
</item>
<item>
    <title>Research: Symbolic Reinforcement Learning</title>
    <link>http://example.org/posts/symbolicrl/</link>
    <pubDate>Mon, 16 Jan 2023 11:00:59 -0400</pubDate>
    <author> Waris Radji, Corentin Léger, Lucas Bardisbanian</author>
    <guid>http://example.org/posts/symbolicrl/</guid>
    <description><![CDATA[Paper published in HAL-Inria (Inria&rsquo;s Research or Technical Reports) during a semester project in my last MSc year.
Abstract Modeling complex problems is a real issue in Reinforcement learning. The goal of this projet is to use a RL model, such as Q-learning, on symbolic data, where the knowledge of the problem would be stored, in the form of qualitative or numerical data (in JSON for example). Instead of only working with numerical data, we could link the data with a certain &rsquo;edition distance&rsquo; which permits to evaluate the proximity of 2 elements.]]></description>
</item>
</channel>
</rss>
