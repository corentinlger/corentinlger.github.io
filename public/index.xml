<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Corentin LEGER</title>
        <link>http://example.org/</link>
        <description>This is my cool site</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 05 Jan 2025 11:00:59 -0400</lastBuildDate>
            <atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Research: When LLMs Play the Telephone Game (ICLR 2025)</title>
    <link>http://example.org/posts/telephonellm/</link>
    <pubDate>Sun, 05 Jan 2025 11:00:59 -0400</pubDate>
    <author>J√©r√©my Perez, Grgur Kovaƒç, Corentin L√©ger, C√©dric Colas, Gaia Molinaro, Maxime Derex, Pierre-Yves Oudeyer, Cl√©ment Moulin-Frier</author>
    <guid>http://example.org/posts/telephonellm/</guid>
    <description><![CDATA[What happens when LLMs play the Telephone game ‚òéÔ∏è? In this paper, we analyse the evolution of texts as they are transmitted between LLM agents ü§ñüí¨ü§ñüí¨ü§ñüí¨
Do text properties converge to attractors üß≤? How is this influenced by the tasküìù and model‚öôÔ∏è?
Abstract As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next.]]></description>
</item>
<item>
    <title>Software: Vivarium</title>
    <link>http://example.org/posts/vivarium/</link>
    <pubDate>Thu, 21 Nov 2024 11:00:59 -0400</pubDate>
    <author>Corentin L√©ger, Cl√©ment Moulin-Frier, Martial Marzloff</author>
    <guid>http://example.org/posts/vivarium/</guid>
    <description><![CDATA[With members of the Flowers team, we developed Vivarium, a multi-agent simulator in Jax. It serves both research and teaching in Artificial Intelligence and Artificial Life.
This software enables creating simple agents with two motors and two sensors, inspired by Braitenberg Vehicles, in a 2D rigid-body physics world (the physics engine is written in Jax-MD). Despite the simplicity of the agents at an individual level, the interactions between them can lead to complex emergent behaviors and scenarios !]]></description>
</item>
<item>
    <title>Hackathon: LeRobot</title>
    <link>http://example.org/posts/lerobot/</link>
    <pubDate>Tue, 15 Oct 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/lerobot/</guid>
    <description><![CDATA[Introduction I participated in the LeRobot Hackathon in Toulouse, organized by the Hugging Face team ü§ó ! It was a great way to get my first steps into real-world reinforcement learning and robotics.
We went from having a very messy table (see below) with a lot of hardware parts to a fully assembled robot in a few hours. It was a robotic arm with a gripper, the Moss v1 and we tried to teach it how to manipulate a cube.]]></description>
</item>
<item>
    <title>Software: Open Source Contributions</title>
    <link>http://example.org/posts/opensource/</link>
    <pubDate>Wed, 12 Jun 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/opensource/</guid>
    <description><![CDATA[Co-developed the LLM-Culture library within the Flowers team. This software enables simulating networks composed of LLMs agents, that can generate text over multiple generations based on their neighbors input, personnality and task. The project also provides tools for analyzing the resulting text dynamics and offers an user-friendly web interface, making it accessible to non-programmers.
Developed a turorial for parallelized hyper parameter search using Optuna in the ReservoirPy machine learning library.]]></description>
</item>
<item>
    <title>Research: Cultural evolution in populations of Large Language Models (Preprint)</title>
    <link>http://example.org/posts/llm_culture/</link>
    <pubDate>Tue, 12 Mar 2024 11:00:59 -0400</pubDate>
    <author>J√©r√©my Perez, Corentin L√©ger, Marcela Ovando-Tellez, Chris Foulon, Joan Dussauld, Pierre-Yves Oudeyer, Cl√©ment Moulin-Frier</author>
    <guid>http://example.org/posts/llm_culture/</guid>
    <description><![CDATA[What can LLMs bring to the study of cultural evolution ü§î?
In this preprint, we present a framework for simulating cultural evolution using LLMs ü¶ú. We study how the dynamics depends on social structure, simulated personalitiesüë•, and whether it has potential attractorsüß≤üîç
Abstract Research in cultural evolution aims at providing causal explanations for the change of culture over time. Over the past decades, this field has generated an important body of knowledge, using experimental, historical, and computational methods.]]></description>
</item>
<item>
    <title>Research: Evolving Reservoirs for Meta Reinforcement Learning (EvoStar 2024)</title>
    <link>http://example.org/posts/er_mrl/</link>
    <pubDate>Tue, 12 Dec 2023 11:00:59 -0400</pubDate>
    <author>Corentin L√©ger*, Gautier Hamon*, Eleni Nisioti, Xavier Hinaut, Cl√©ment Moulin-Frier</author>
    <guid>http://example.org/posts/er_mrl/</guid>
    <description><![CDATA[Paper presented at EvoStar 2024 (Long Talk).
Abstract Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning.
In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development.]]></description>
</item>
<item>
    <title>Hackathon: Ebiose</title>
    <link>http://example.org/posts/ebiose/</link>
    <pubDate>Fri, 17 Nov 2023 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/ebiose/</guid>
    <description><![CDATA[Introduction Participated to a project called Ebiose during a 2 days hackathon with a team of 4 people. It focuses on a multi-language-based-agent system to solve tasks. In this system, agents are composed of LLM (e.g. GPT-3.5) coupled with a specific prompt. The structure of the multi-agent system followes a predetermined sequence, where one agent answers a question, another verifies the answer, and a final agent synthesizes both responses. This collaboration is inspired by the Autogen Framework, emphasizing coordinated efforts among agents.]]></description>
</item>
<item>
    <title>Research: Symbolic Reinforcement Learning (HAL Inria)</title>
    <link>http://example.org/posts/symbolicrl/</link>
    <pubDate>Mon, 16 Jan 2023 11:00:59 -0400</pubDate>
    <author> Waris Radji, Corentin L√©ger, Lucas Bardisbanian</author>
    <guid>http://example.org/posts/symbolicrl/</guid>
    <description><![CDATA[Paper published in HAL-Inria (Inria&rsquo;s Research or Technical Reports) during a semester project in my last MSc year.
Abstract Modeling complex problems is a real issue in Reinforcement learning. The goal of this projet is to use a RL model, such as Q-learning, on symbolic data, where the knowledge of the problem would be stored, in the form of qualitative or numerical data (in JSON for example). Instead of only working with numerical data, we could link the data with a certain &rsquo;edition distance&rsquo; which permits to evaluate the proximity of 2 elements.]]></description>
</item>
</channel>
</rss>
