<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Reinforcement Learning - Tag - Corentin LEGER</title>
        <link>http://example.org/tags/reinforcement-learning/</link>
        <description>Reinforcement Learning - Tag - Corentin LEGER</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 15 Oct 2024 11:00:59 -0400</lastBuildDate><atom:link href="http://example.org/tags/reinforcement-learning/" rel="self" type="application/rss+xml" /><item>
    <title>Hackathon: LeRobot</title>
    <link>http://example.org/posts/lerobot/</link>
    <pubDate>Tue, 15 Oct 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/lerobot/</guid>
    <description><![CDATA[Introduction I participated in the LeRobot Hackathon in Toulouse, organized by the Hugging Face team ü§ó ! It was a great way to get my first steps into real-world reinforcement learning and robotics.
We went from having a very messy table (see below) with a lot of hardware parts to a fully assembled robot in a few hours. It was a robotic arm with a gripper, the Moss v1 and we tried to teach it how to manipulate a cube.]]></description>
</item>
<item>
    <title>Software: Open Source Contributions</title>
    <link>http://example.org/posts/opensource/</link>
    <pubDate>Wed, 12 Jun 2024 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/opensource/</guid>
    <description><![CDATA[Developed the LLM-Culture library. This software enables simulating networks composed of LLMs agents, that can generate text over multiple generations based on their neighbors input, personnality and task. The project also provides tools for analyzing the resulting text dynamics and offers an user-friendly web interface, making it accessible to non-programmers.
Developed a turorial for hyper parameter search using Optuna in the ReservoirPy machine learning library. The tutorial covers sequential and parallelized hyperparameter search on local machines using the joblib package.]]></description>
</item>
<item>
    <title>Research: Evolving Reservoirs for Meta Reinforcement Learning</title>
    <link>http://example.org/posts/er_mrl/</link>
    <pubDate>Tue, 12 Dec 2023 11:00:59 -0400</pubDate>
    <author>Corentin L√©ger*, Gautier Hamon*, Eleni Nisioti, Xavier Hinaut, Cl√©ment Moulin-Frier</author>
    <guid>http://example.org/posts/er_mrl/</guid>
    <description><![CDATA[Paper presented at EvoStar 2024 (Long Talk).
Abstract Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning.
In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development.]]></description>
</item>
<item>
    <title>Software: Rising Sun</title>
    <link>http://example.org/posts/risingsun/</link>
    <pubDate>Wed, 12 Jul 2023 11:00:59 -0400</pubDate>
    <author>Corentin</author>
    <guid>http://example.org/posts/risingsun/</guid>
    <description><![CDATA[To try to beat friends on the combat phases of the &ldquo;Rising Sun&rdquo; board game, I created this simplified gymnasium implementation of the game. The project also incorporates a python script to train a single RL agent on the environment. This agent can currently only be trained against hard-coded players (either random of with heuristics).
The next step will be to add multi-agents training to the project. Then, it will be interesting to explore the path of self play to see how complex the behaviors of the agent can become !]]></description>
</item>
<item>
    <title>Research: Symbolic Reinforcement Learning</title>
    <link>http://example.org/posts/symbolicrl/</link>
    <pubDate>Mon, 16 Jan 2023 11:00:59 -0400</pubDate>
    <author> Waris Radji, Corentin L√©ger, Lucas Bardisbanian</author>
    <guid>http://example.org/posts/symbolicrl/</guid>
    <description><![CDATA[Paper published in HAL-Inria (Inria&rsquo;s Research or Technical Reports) during a semester project in my last MSc year.
Abstract Modeling complex problems is a real issue in Reinforcement learning. The goal of this projet is to use a RL model, such as Q-learning, on symbolic data, where the knowledge of the problem would be stored, in the form of qualitative or numerical data (in JSON for example). Instead of only working with numerical data, we could link the data with a certain &rsquo;edition distance&rsquo; which permits to evaluate the proximity of 2 elements.]]></description>
</item>
</channel>
</rss>
