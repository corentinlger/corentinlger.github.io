<!DOCTYPE html>
<html lang="en">

<head>
   <title>Corentin Léger</title>
   <meta charset="UTF-8" />
   <meta name="viewport" content="width=device-width, initial-scale=1.0" />
   <!-- <link rel="icon" href="imgs/toff.png" /> -->

   <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" />
   <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Lato:400,700" />
   <link rel="stylesheet" href="css/style.css" />

   <!-- Google tag (gtag.js) -->
   <script async src="https://www.googletagmanager.com/gtag/js?id=G-5P1Z9TH4JQ"></script>
   <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
         dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-5P1Z9TH4JQ");
   </script>
   <script src="https://kit.fontawesome.com/3e67022814.js" crossorigin="anonymous"></script>

   <script src="js/hidebib.js"></script>
   <script async defer src="https://buttons.github.io/buttons.js"></script>
   <script
      src="https://sdk.feedback.one/v0/core.min.js"
      data-project-id="01944737-f6a9-78a0-bdc3-3f99e08df546"
      defer
   ></script>
</head>

<body>
   <main class="container" style="max-width: 950px; margin: 0 auto;">
      <!-- Header -->
      <header class="mt-3">
         <div class="topnav">
            <div class="topnav-container">
                <div class="topnav-left">
                    <a href="#" class="logo-link">
                        <div class="logo">
                            <img src="imgs/toff.png" class="landing">   

                            <div>
                                <span class="name">Corentin Léger</span>
                                <span class="slogan">AI/ML Research Engineer</span>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="topnav-right">
                    <a href="#papers">Research</a>
                    <a href="#libs">Open Source</a>
                    <!-- <a href="#teaching">Teaching</a> -->
                    <!-- <a href="#projects">Projects</a> -->
                    <a target="_blank" href="leger_corentin_resume.pdf">CV</a>
                </div>
            </div>
        </div>

           
         <div class="row d-flex">
            <div class="col-md-8">
               <div>
                  <p>
                     Hi, I’m Corentin, a Research Engineer at 
                     <a href="https://huggingface.co/paris-noah" target="_blank">Huawei Noah's Ark Lab</a> Paris,
                     working on LLMs, AutoML and RL
                     under the supervision of 
                     <a href="https://scholar.google.com/citations?user=s0njcGgAAAAJ&hl=en" target="_blank">Balázs Kégl</a>.
                 </p>
                 <p> 
                     Prior to that, I was a Research Engineer at 
                     <a href="https://www.inria.fr/en" target="_blank">Inria</a>   
                     in the 
                     <a href="https://flowers.inria.fr/" target="_blank">Flowers</a>
                     lab, where I developed multi-agent systems,
                     supervised by
                     <a href="https://scholar.google.fr/citations?user=rBnV60QAAAAJ&hl=en" target="_blank">Clément Moulin Frier</a>. 
                     During my MSc in Computer and Cognitive Sciences at  
                     <a href="https://ensc.bordeaux-inp.fr/fr" target="_blank">ENSC</a>,
                     I also interned at 
                     <a href="https://www.connectiv-it.com/" target="_blank">Connectiv-IT</a>
                     as a Data Scientist,
                     and at  
                     <a href="https://flowers.inria.fr/" target="_blank">Inria Flowers</a>
                     doing Reinforcement Learning research.
                 </p> 
                 <!-- <p>
                     During my MSc in Computer and Cognitive Sciences at  
                     <a href="https://ensc.bordeaux-inp.fr/fr" target="_blank">ENSC</a>,
                     I also interned at 
                     <a href="https://www.connectiv-it.com/" target="_blank">Connectiv-IT</a>
                     as a Data Scientist,
                     and at  
                     <a href="https://flowers.inria.fr/" target="_blank">Inria Flowers</a>
                     doing Reinforcement Learning research.
                 </p> -->
                 <p>
               <!-- <p>
                  I have a strong foundation in Machine Learning and Software Engineering, 
                  and I'm particularly interested in 
                  Reinforcement Learning, Evolutionary Strategies, Multi-agent systems and LLMs.
               </p> -->
                 Among a lot of other things, I love sports and play volley-ball at a national level
                 (<a href="https://drive.google.com/file/d/1FhwyMhKOxN7QKWM3JcCXx-rfS5ZLsxHw/view?usp=sharing" target="_blank">bronze medal</a>
                 in the 2023 French University Championship!).
                 </p>
                  
                  <p class="text-left">Contact: <a href="mailto:corentin.lger@gmail.com">corentin.lger@gmail.com</a></p>
               </div>
               <aside class="contact">
                  <a target="_blank" href="https://x.com/corentinlger">
                     <img title="Twitter" src="icons/twitter.svg" alt="Twitter" /></a>
                  <a target="_blank" href="https://scholar.google.com/citations?user=V-qyPxkAAAAJ&hl=en">
                     <img title="Google Scholar" src="icons/scholar.svg" alt="Google Scholar" /></a>
                  <a target="_blank" href="https://github.com/corentinlger">
                     <img title="GitHub" src="icons/github.svg" alt="GitHub" /></a>
                  <a target="_blank" href="https://linkedin.com/in/corentin-l">
                     <img title="LinkedIn" src="icons/linkedin.svg" alt="LinkedIn" /></a>
               </aside>
            </div>
            <div class="col-12 col-md-4 mt-3 order-first order-md-last text-center">
               <div class="face">
                  <img src="imgs/toff.png" alt="Avatar" width="230" />
               </div>
            </div>
         </div>
      </header>

 
      <!-- Publications -->
      <section>
         <h2 id="papers">Research</h2>
         <p>
            <!-- I'm particularly interested in 
            Reinforcement Learning, Evolutionary Strategies, Multi-agent systems and LLMs. -->
           You can check my <a href="https://scholar.google.com/citations?user=V-qyPxkAAAAJ&hl=en" target="_blank">Google
            Scholar</a> for more details about the publications.
         </p>
         <p>
            
         </p>


         <!-- LLM persuasion paper -->
         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/persuasion.png" alt="llm_persuasion" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://drive.google.com/file/d/1-lkHBkZxOIYp5Syfk34BJ0RsPwcAKog_/view?usp=sharing" target="_blank" style="color: #0047ab"><strong>
                     Optimizing for Persuasion Improves LLM Generalization: Evidence from Quality-Diversity Evolution of Debate Strategies
                     </strong></a><br />
                  <a href="https://github.com/akseljoonas"> A J Reedi</a>,
                  <strong>C Léger</strong>,
                  <a href="https://julienp.netlify.app/"> J Pourcel</a>,
                  <a href="https://github.com/LorisGaven"> L Gaven</a>,
                  <a href="https://openreview.net/profile?id=~Perrine_Charriau1"> Perrine Charriau</a>,
                  <a href="https://guillaumepourcel.github.io/">G Pourcel</a>
                  <br />
                  <em>MTI-LLM @ NeurIPS</em>, 2025
               </p>
               <div class="paper" id="llm_persuasion">
                  <a href="https://drive.google.com/file/d/1-lkHBkZxOIYp5Syfk34BJ0RsPwcAKog_/view?usp=sharing" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                     <a href="https://github.com/flowersteam/llm_persuasion" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        code
                     </button></a>
                  <!-- <a href="TODO" target="_blank"><button
                        type="button" class="btn btn-outline-primary btn-sm">
                        tweet
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('llm_persuasion')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre>
@misc{TODO,
   title={Optimizing for Persuasion Improves LLM Generalization: Evidence from Quality-Diversity Evolution of Debate Strategies}, 
   author={TODO},
   year={2025},
   eprint={TODO},
   archivePrefix={TODO},
   primaryClass={TODO},
   url={TODO}, 
}</pre> -->
               </div>
            </div>
         </div>


         <!-- LLM Models & HPs paper -->
         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/llm_hps.png" alt="llm_hps" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://openreview.net/forum?id=Ppo2SETqcE" target="_blank" style="color: #0047ab"><strong>
                     In-Context Meta-Learning with Large Language Models for Automated Model and Hyperparameter Selection
                     </strong></a><br />
                  <a href="https://www.linkedin.com/in/youssef-attia-el-hili/"> Y Attia El Hili</a>,
                  <a href="https://albertcthomas.github.io/"> A Thomas</a>,
                  <a href="https://abenechehab.github.io/"> A Benechehab</a>,
                  <strong>C Léger</strong>,
                  <a href="https://scholar.google.com/citations?user=4UoL5VsAAAAJ&hl=fr"> C Ancourt</a>,
                  <a href="https://scholar.google.com/citations?user=s0njcGgAAAAJ&hl=en&oi=ao">B Kégl</a>
                  <br />
                  <em>LLM-eval @ NeurIPS</em>, 2025
               </p>
               <div class="paper" id="llm_hps">
                  <a href="https://openreview.net/pdf?id=Ppo2SETqcE" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                  <!-- <a href="TODO" target="_blank"><button
                        type="button" class="btn btn-outline-primary btn-sm">
                        tweet
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('llm_persuasion')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre> -->
<!-- Wait until gets published on google scholar to get bibtex -->
<!-- @misc{TODO,
   title={In-Context Meta-Learning with Large Language Models for Automated Model and Hyperparameter Selection}, 
   author={TODO},
   year={2025},
   eprint={TODO},
   archivePrefix={TODO},
   primaryClass={TODO},
   url={TODO}, 
}</pre>   -->
               </div>
            </div>
         </div>


         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/telephonegame.png" alt="telephonellm" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://arxiv.org/abs/2407.04503" target="_blank" style="color: #0047ab"><strong>
                     When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions
                     </strong></a><br />
                  <a href="https://scholar.google.com/citations?user=isuFqLIAAAAJ&hl=fr"> J Perez</a>,
                  <a href="https://grgkovac.github.io/"> G Kovač</a>,
                  <strong>C Léger</strong>,
                  <a href="https://ccolas.github.io/"> C Colas</a>,
                  <a href="https://gaiamolinaro.github.io/"> G Molinaro</a>,
                  <a href="https://maximederex.weebly.com/">M Derex</a>,
                  <a href="http://www.pyoudeyer.com/"> PY Oudeyer</a>,
                  <a href="https://clement-moulin-frier.github.io/"> C Moulin-Frier</a>
                  <br />
                  <em>ICLR</em>, 2025
               </p>
               <div class="paper" id="telephonellm">
                  <a href="https://arxiv.org/pdf/2407.04503" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                  <a href="https://sites.google.com/view/telephone-game-llm" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        website
                     </button></a>
                  <a href="https://x.com/Jeremy__Perez/status/1810729621349880194" target="_blank"><button
                        type="button" class="btn btn-outline-primary btn-sm">
                        tweet
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('telephonellm')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre>
@inproceedings{perez2025llms,
   title={When LLMs play the telephone game: Cultural attractors as conceptual tools to evaluate LLMs in multi-turn settings},
   author={Perez, J{\'e}r{\'e}my and Kova{\v{c}}, Grgur and L{\'e}ger, Corentin and Colas, C{\'e}dric and Molinaro, Gaia and Derex, Maxime and Oudeyer, Pierre-Yves and Moulin-Frier, Cl{\'e}ment},
   booktitle={The Thirteenth International Conference on Learning Representations},
   year={2025}
}
</pre>   
               </div>
            </div>
         </div>

         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/llmculture.png" alt="llm_culture" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://arxiv.org/abs/2403.08882" target="_blank" style="color: #0047ab"><strong>
                     Cultural evolution in populations of Large Language Models
                     </strong></a><br />
                  <a href="https://scholar.google.com/citations?user=isuFqLIAAAAJ&hl=fr"> J Perez</a>,
                  <strong>C Léger</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=a9FasrMAAAAJ&hl=fr"> M Ovando-Tellez</a>,
                  <a href="https://scholar.google.fr/citations?user=YiFkOzkAAAAJ&hl=fr"> C Foulon</a>,
                  <a href="https://www.linkedin.com/in/joan-dussauld-060307188/?originalSubdomain=fr"> J Dussauld</a>,
                  <a href="http://www.pyoudeyer.com/"> PY Oudeyer</a>,
                  <a href="https://clement-moulin-frier.github.io/"> C Moulin-Frier</a>
                  <br />

                  <em>arXiv</em>, 2024
               </p>
               <div class="paper" id="llm-culture">
                  <a href="https://arxiv.org/pdf/2403.08882" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                  <a href="https://github.com/flowersteam/LLM-Culture" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        code
                     </button></a>
                  <a href="https://x.com/Jeremy__Perez/status/1772290143761596772" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        tweet
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('llm-culture')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre>
@article{perez2024cultural,
   title={Cultural evolution in populations of Large Language Models},
   author={Perez, J{\'e}r{\'e}my and L{\'e}ger, Corentin and Ovando-Tellez, Marcela and Foulon, Chris and Dussauld, Joan and Oudeyer, Pierre-Yves and Moulin-Frier, Cl{\'e}ment},
   journal={arXiv preprint arXiv:2403.08882},
   year={2024}
}</pre>
               </div>
            </div>
         </div>

         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/ermrl.png" alt="er-mrl" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://arxiv.org/abs/2312.06695" target="_blank" style="color: #0047ab"><strong>
                     Evolving reservoirs for Meta Reinforcement Learning
                       </strong></a><br />
                  *<strong>C Léger</strong>,
                  *<a href="https://reytuag.github.io/gautier-hamon/">G Hamon</a>,
                  <a href="https://eleninisioti.github.io/#/"> E Nisioti</a>,
                  <a href="https://sites.google.com/site/xavierhinaut/"> X Hinaut</a>,
                  <a href="https://clement-moulin-frier.github.io/"> C Moulin-Frier</a> <br />
                  <em>EvoStar [Long Talk]</em>, 2024
               </p>

               <div class="paper" id="er-mrl">
                  <a href="https://arxiv.org/pdf/2312.06695" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                  <a href="https://github.com/corentinlger/ER-MRL" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        code
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('er-mrl')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre>
@inproceedings{leger2024evolving,
   title={Evolving Reservoirs for Meta Reinforcement Learning},
   author={L{\'e}ger, Corentin and Hamon, Gautier and Nisioti, Eleni and Hinaut, Xavier and Moulin-Frier, Cl{\'e}ment},
   booktitle={International Conference on the Applications of Evolutionary Computation (Part of EvoStar)},
   pages={36--60},
   year={2024},
   organization={Springer}
}</pre>
               </div>
            </div>
         </div>

         <div class="image-container row mb-4">
            <div class="col-2 mt-3">
               <img src="imgs/pubs/symbolic-rl.png" alt="symbolic-rl" width="180" />
            </div>
            <div class="col-10">
               <p>
                  <a href="https://inria.hal.science/hal-04103795" target="_blank" style="color: #0047ab"><strong>
                     Early Empirical Results on Reinforcement Symbolic Learning
                     </strong></a><br />
                  <a href="https://warisradji.com/"> W Radji</a>,
                  <strong>C Léger</strong>,
                  <a href="https://scholar.google.com/citations?user=6csF224AAAAJ&hl=en"> L Bardisbanian</a> <br />
                  <em>HAL Inria</em>, 2023
               </p>
               <div class="paper" id="symbolic-rl">
                  <a href="https://inria.hal.science/hal-04103795v1/document" target="_blank"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        paper
                     </button></a>
                  <a shape="rect" href="javascript:togglebib('symbolic-rl')" class="togglebib"><button type="button"
                        class="btn btn-outline-primary btn-sm">
                        bibtex
                     </button></a>
                  <pre>
@phdthesis{radji2023early,
   title={Early Empirical Results on Reinforcement Symbolic Learning},
   author={Radji, Waris and L{\'e}ger, Corentin and Bardisbanian, Lucas},
   year={2023},
   school={Inria \& Labri, Univ. Bordeaux}
}</pre>
               </div>
            </div>
         </div>
      </section>

      <!-- TODO: do a short desc + read more button -->
      <!-- Libraries -->
      <section>
         <h2 id="libs">Open Source</h2>
         <p>
            Here is a list of open source projects I contributed to, you can check my
            <a href="https://github.com/corentinlger" target="_blank">GitHub</a> profile for more details. 
         </p>

         <!-- Vivarium -->
         <div class="project-item">
            <p>
               <a href="https://github.com/flowersteam/vivarium" target="_blank" style="color: #0047ab"><strong>Vivarium</strong></a>
               <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
                  <a class="github-button" href="https://github.com/flowersteam/vivarium" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
               </span>: 
               Multi-agent Jax simulator in a 2D physics-based world.
               <a href="javascript:void(0)" onclick="toggleProjectDesc('vivarium-desc')" class="see-more">see more</a>
            </p>
            <div id="vivarium-desc" class="project-desc" style="display: none;">
               
               This simulator features simulated robots with sensors and motors, inspired by
               <a href="https://en.wikipedia.org/wiki/Braitenberg_vehicles" target="_blank">Braitenberg vehicles</a>.
               It serves both research and <a href="//github.com/flowersteam/vivarium/tree/main/notebooks/sessions" target="_blank">teaching</a> in AI & ALife. 
               The simulations can be hosted on a server, and interacted with in real time from a web interface or Jupyter Notebooks.

               <div style="text-align: center; margin-top: 30px;">
                     <img src="imgs/libs/vivarium_sim.gif" alt="Vivarium Simulation" style="max-width: 50%; height: auto; border-radius: 4px; padding: 5px; display: block; margin: 0;">
                  <!-- <img src="imgs/libs/vivarium_sim.gif" alt="Vivarium Simulation" style="max-width: 50%; height: auto; border-radius: 4px; padding: 5px;"> -->
               </div>
            </div>
         </div>
         
         <!-- LLM-Culture -->
         <div class="project-item">
            <p>
               <a href="https://github.com/flowersteam/LLM-Culture" target="_blank" style="color: #0047ab"><strong>LLM-Culture</strong></a>
               <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
                  <a class="github-button" href="https://github.com/flowersteam/LLM-Culture" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
               </span>: 
               Simulating text evolution in networks of LLMs.
               <a href="javascript:void(0)" onclick="toggleProjectDesc('llm-culture-desc')" class="see-more">see more</a>
            </p>
            <div id="llm-culture-desc" class="project-desc" style="display: none;">
               This software enables simulating networks of LLMs that generate text over multiple generations based on their personality, task, and neighbors' input. 
               The project also provides NLP tools for analyzing the resulting text dynamics, as well as a web interface.
            </div>
         </div>

         <!-- KanRL -->
         <div class="project-item">
            <p>
               <a href="https://github.com/riiswa/kanrl" target="_blank" style="color: #0047ab"><strong>KanRL</strong></a>
               <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
                  <a class="github-button" href="https://github.com/riiswa/kanrl" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
               </span>: 
               Combine RL and Kolmogorov-Arnold Networks (KANs).
               <a href="javascript:void(0)" onclick="toggleProjectDesc('kanrl-desc')" class="see-more">see more</a>
            </p>
            <div id="kanrl-desc" class="project-desc" style="display: none;">
               I helped create a 
               <a href="https://huggingface.co/spaces/riiswa/RL-Interpretable-Policy-via-Kolmogorov-Arnold-Network" target="_blank"> 
               Hugging Face app</a> to interpret trained RL policies.
               I also <a href="https://github.com/riiswa/kanrl/tree/ppo" target=_blank>implemented</a> 
               and tested  the performance of Policy Gradient and PPO algorithms with both KANs and MLPs.
            </div>
         </div>


         <p>I also fixed a few issues in the
            <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank">Stable-Baselines3</a>
            Reinforcement Learning library, 
            and created a tutorial for parallelized hyperparameter search on remote clusters in 
            <a href="https://github.com/reservoirpy/reservoirpy" target="_blank">ReservoirPy</a>.
         </p>

      </section>

      <!-- <section>
         <h2 id="libs">Open Source</h2>
         <p>
            Here is a list of open source projects I contributed to, you can check my
            <a href="https://github.com/corentinlger" target="_blank">GitHub</a> profile for more details. 
         </p>

         Vivarium
         <p>
            <a href="https://github.com/flowersteam/vivarium" target="_blank" style="color: #0047ab"><strong>Vivarium</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/flowersteam/vivarium" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
            Multi-agent Jax simulator in a 2D physics-based world.
            <a href="javascript:void(0)" onclick="toggleProjectDesc('vivarium-desc')" class="see-more">see more</a>
         </p>
         <div id="vivarium-desc" class="project-desc" style="display: none;">
            
            This simulator features simulated robots with sensors and motors, inspired by
            <a href="https://en.wikipedia.org/wiki/Braitenberg_vehicles" target="_blank">Braitenberg vehicles</a>.
            It serves both research and <a href="//github.com/flowersteam/vivarium/tree/main/notebooks/sessions" target="_blank">teaching</a> in AI & ALife. 
            The simulations can be hosted on a server, and interacted with in real time from a web interface or Jupyter Notebooks.

            <div style="text-align: center; margin-top: 30px;">
                  <img src="imgs/libs/vivarium_sim.gif" alt="Vivarium Simulation" style="max-width: 50%; height: auto; border-radius: 4px; padding: 5px; display: block; margin: 0;">
               <img src="imgs/libs/vivarium_sim.gif" alt="Vivarium Simulation" style="max-width: 50%; height: auto; border-radius: 4px; padding: 5px;">
            </div>
         </div>

         
         LLM-Culture
         <p>
            <a href="https://github.com/flowersteam/LLM-Culture" target="_blank" style="color: #0047ab"><strong>LLM-Culture</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/flowersteam/LLM-Culture" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
            Simulating text evolution in networks of LLMs.
            <a href="javascript:void(0)" onclick="toggleProjectDesc('llm-culture-desc')" class="see-more">see more</a>
         </p>
         <div id="llm-culture-desc" class="project-desc" style="display: none;">
            This software enables simulating networks of LLMs that generate text over multiple generations based on their personality, task, and neighbors' input. 
            The project also provides NLP tools for analyzing the resulting text dynamics, as well as a web interface.
         </div>

         

         KanRL
         <p>
            <a href="https://github.com/riiswa/kanrl" target="_blank" style="color: #0047ab"><strong>KanRL</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/riiswa/kanrl" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
            Combine RL and Kolmogorov-Arnold Networks (KANs).
            <a href="javascript:void(0)" onclick="toggleProjectDesc('kanrl-desc')" class="see-more">see more</a>
         </p>
         <div id="kanrl-desc" class="project-desc" style="display: none;">
            I helped create a 
            <a href="https://huggingface.co/spaces/riiswa/RL-Interpretable-Policy-via-Kolmogorov-Arnold-Network" target="_blank"> 
            Hugging Face app</a> to interpret trained RL policies.
            I also <a href="https://github.com/riiswa/kanrl/tree/ppo" target=_blank>implemented</a> 
            and tested  the performance of Policy Gradient and PPO algorithms with both KANs and MLPs.
         </div>

         <p>I also fixed a few issues in the
            <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank">Stable-Baselines3</a>
            Reinforcement Learning library, 
            and created a tutorial for parallelized hyperparameter search on remote clusters in 
            <a href="https://github.com/reservoirpy/reservoirpy" target="_blank">ReservoirPy</a>.
         </p>
         
      </section> -->


      <!-- <section>
         <h2 id="libs">Open Source</h2>
         <p>
            Here is a list of open source projects I contributed to, you can check my
            <a href="https://github.com/corentinlger" target="_blank">GitHub</a> profile for more details. 
         </p>

         
         <p>
            <a href="https://github.com/flowersteam/LLM-Culture" target="_blank" style="color: #0047ab"><strong>LLM-Culture</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/flowersteam/LLM-Culture" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
             This software enables simulating networks of LLMs, that generate text over multiple generations based on their personality, task and neighbors' input. The project also provides tools for analyzing the resulting text dynamics and a web interface.
         </p>
         <p>
            <a href="https://github.com/flowersteam/vivarium" target="_blank" style="color: #0047ab"><strong>Vivarium</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/flowersteam/vivarium" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
             Multi-agent simulator in a 2D physics-based world, implemented in Jax, serving both research and <a href="//github.com/flowersteam/vivarium/tree/main/notebooks/sessions" target="_blank">teaching</a> in AI & ALife. The simulations can be hosted on a server, and interacted with in real time from a web interface or Jupyter Notebooks.
         </p>
         <p>
            <a href="https://github.com/riiswa/kanrl" target="_blank" style="color: #0047ab"><strong>KanRL</strong></a>
            <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
               <a class="github-button" href="https://github.com/riiswa/kanrl" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
            </span>: 
               Project studying the combination of RL and Kolmogorov-Arnold Networks (KANs). 
               I helped create a 
               <a href="https://huggingface.co/spaces/riiswa/RL-Interpretable-Policy-via-Kolmogorov-Arnold-Network" target="_blank"> 
               Hugging Face app</a> to interpret RL policies, 
               and <a href="https://github.com/riiswa/kanrl/tree/ppo" target=_blank>benchmarked</a> 
               the performance of Policy Gradient and PPO algorithms using both KANs and MLPs.
         </p>
         
         <p>I also fixed a few issues in the popular 
            <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank">Stable-Baselines3</a>
            Reinforcement Learning library.
            I also created a tutorial for parallelized hyperparameter search in the
            <a href="https://github.com/reservoirpy/reservoirpy" target="_blank">ReservoirPy</a>
            Machine Learning library (covering how to scale it on remote clusters).
         </p>
      </section> -->
<!-- 
         <h4>Additional contributions</h4>
         <p>
               <a href="https://github.com/DLR-RM/stable-baselines3" target="_blank" style="color: #0047ab"><strong>Stable-Baselines3</strong></a>
               <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
                  <a class="github-button" href="https://github.com/DLR-RM/stable-baselines3" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
               </span>: 
                Fixed a few issues in the Stable-Baselines3 Reinforcement Learning library.
         </p>
         <p>   
               <a href="https://github.com/reservoirpy/reservoirpy" target="_blank" style="color: #0047ab"><strong>ReservoirPy</strong></a>
               <span class="d-inline-block" style="vertical-align: middle; margin: 0 5px;">
                  <a class="github-button" href="https://github.com/reservoirpy/reservoirpy" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star on GitHub">Star</a>
               </span>: 
             Created a tutorial for parallelized hyperparameter search in the ReservoirPy ML library. 
            It covers this process on local machines, as well as how to scale it on remote clusters.
         </p>
      </section> -->
         

      <!-- Teaching -->
      <section>
         <h2 id="teaching">Teaching</h2>


  
         <div class="row">
            <div class="col-2 mt-3">
               <a href="https://www.upf.edu/" target="_blank">
                  <img src="imgs/teaching/Logo_UPF.jpg" alt="UPF" width="180" /></a>
            </div>
            <div class="col-10">
               <p>
                     January 2025 - Teaching assistant, Introduction to multi-agent systems (9h)
               </p>
            </div>
         </div>
      </section>
   
   <!-- # TODO: See if keep the projects section or not, surely yes if wanna apply to PhDs cause cool things here -->
   <!-- Projects -->
   <section>
      <!-- <h2 id="projects">Projects</h2> -->
         <h2 id="projects">Hackathons</h2>
         <!-- <h4 id="hackathons">Hackathons</h4> -->
            <p>🧠 <a href="https://sites.google.com/view/hack1robo/projets-%C3%A9d-3-nov-2024?authuser=0" target="_blank">Hack1Robo 2024 (first place)</a>: 
            Optimized persuasion skills of LLMs in debate tournaments via prompt evolution. 
            Used a Quality Diversity method to evolve the strategies of debaters LLMs.</p>
            <p>🤖 <a href="https://github.com/huggingface/lerobot_hackathon_oct2024">Hugging Face LeRobot</a>: 
            Assembled a robotic arm and created a real-world
            RL environment for objects manipulation. Trained the robotic arm using both Behavioral cloning
            and online Reinforcement Learning.</p>
            <p>📚 <a href="https://sites.google.com/view/hack1robo/projets-%C3%A9d-1-juin-2023?authuser=0">Hack1Robo 2023</a>: 
            Simulated text evolution in populations of LLMs, and analyze the resulting dynamics (inspired by works in cultural evolution). 
            This later led to the publication of 2 papers.</p>
            <p>🧬 <a href="https://hackatechbordeaux.inria.fr/" target="_blank"">Inria Hackatech 2023</a>: 
            Optimized multi-LLM agent systems strategies via prompt evolution.
            Reached GPT-4 level on math tasks with evolved systems of GPT-3.5 agents. 
            This led to a startup creation: <a href="https://ebiose.com/" target="_blank">Ebiose</a>.</p>

      </section>

   </main>

        <!-- News -->
      <!-- <section>
         <h2 id="news">News</h2>
         <div class="news">
            <ul>
               <li>
                  <strong>[Dec 2024]</strong> I gave a keynote on 'Agent Learning in Open-Endedness' at the <a href="https://imol-workshop.github.io/"
                        target="_blank">IMOL Workshop</a> at NeurIPS 2024. Slides are available <a href="https://samvelyan.com/slides/imol_2024.pdf"
                        target="_blank">here</a>.
               </li>
               <li>
                  <strong>[Oct 2024]</strong> I have joined <a href="https://deepmind.google/"
                        target="_blank">Google DeepMind</a> as a Senior Research Scientist in the Open-Endedness Team.
               </li>
               <li>
                  <strong>[Sep 2024]</strong> <a href="https://arxiv.org/abs/2402.16822"
                     target="_blank">Rainbow Teaming</a> and 
                     <a href="https://arxiv.org/abs/2311.10090" target="_blank">JaxMARL</a> have been accepted to 
                     <a href="https://neurips.cc/Conferences/2024" target="_blank">NeurIPS 2024</a>.
               </li>
               <li>
                  <strong>[Apr 2024]</strong> We released <a href="https://ai.meta.com/blog/meta-llama-3/"
                     target="_blank">Meta Llama 3</a>, the most capable openly available LLM to date. See our <a
                     href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" target="_blank">model card</a>.
               </li>
               <li>
                  <strong>[Feb 2024]</strong> We released <a href="https://arxiv.org/abs/2402.16822"
                     target="_blank">Rainbow Teaming</a>, a new approach for generating diverse adversarial prompts!
               </li>
               <li>
                  <strong>[Jan 2024]</strong> <a href="https://arxiv.org/abs/2401.13460" target="_blank">MADRID</a> has 
                  been accepted to <a href="https://www.aamas2024-conference.auckland.ac.nz/" target="_blank">AAMAS 2024</a>.
               </li>
               <li>
                  <strong>[Sep 2023]</strong> <a href="https://arxiv.org/abs/2212.07489" target="_blank">SMACv2</a> has
                  been accepted to <a href="https://neurips.cc/Conferences/2023" target="_blank">NeurIPS 2023</a>.
               </li>
               <li>
                  <strong>[Jul 2023]</strong> Co-organizing
                  <a href="https://sites.google.com/view/aloe2023" target="_blank">2nd Workshop on Agent Learning in
                     Open-Endedness (ALOE)</a> at <a href="https://neurips.cc/Conferences/2023" target="_blank">NeurIPS
                     2023</a>.
               </li>
               <li>
                  <strong>[Mar-May 2023]</strong> Invited talks at
                  <a href="https://sites.google.com/view/berkeleymarl" target="_blank">UC Berkeley MARL
                     Seminar</a>,
                  <a href="https://www.instadeep.com" target="_blank">InstaDeep</a>,
                  and <a href="https://sites.google.com/view/university-of-maryland-marl" target="_blank">University of
                     Maryland</a>.
               </li>
               <li>
                  <strong>[Feb 2023]</strong> <a href="https://arxiv.org/abs/2303.03376" target="_blank">MAESTRO</a> has
                  been accepted to <a href="https://iclr.cc/Conferences/2023" target="_blank">ICLR 2023</a>.
               </li>
               <li>
                  <strong>[Dec 2022]</strong> We released
                  <a href="https://github.com/oxwhirl/smacv2" target="_blank">SMACv2</a>, an improved version of the
                  <a href="https://github.com/oxwhirl/smac" target="_blank">StarCraft Multi-Agent Challenge</a>.
               </li>
            </ul>
         </div>
      </section> -->



<footer class="mt-5 text-center">
    <p>
        <a href="https://samvelyan.com/" target="_blank">Website credits</a>
    </p>
</footer>

<script>
   hideallbibs();

   function toggleProjectDesc(id) {
      var element = document.getElementById(id);
      if (element.style.display === 'none') {
         element.style.display = 'block';
      } else {
         element.style.display = 'none';
      }
   }
</script>
</body>

</html>
